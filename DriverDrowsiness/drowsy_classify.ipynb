{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:08.558304Z",
     "start_time": "2023-11-24T22:59:05.339050Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_drowsy_dataset_dir = './data/original_dataset/Drowsy'\n",
    "original_nondrowsy_dataset_dir = './data/original_dataset/NonDrowsy'\n",
    "manual_annotation_train_drowsy_dir = './data/manual_annotate/train/Drowsy'\n",
    "manual_annotation_train_nondrowsy_dir = './data/manual_annotate/train/NonDrowsy'\n",
    "manual_annotation_test_drowsy_dir = './data/manual_annotate/test/Drowsy'\n",
    "manual_annotation_test_nondrowsy_dir = './data/manual_annotate/test/NonDrowsy'\n",
    "manual_annotation_nondrowsy_dir = './data/manual_annotate/NonDrowsy'\n",
    "train_dir = './data/manual_annotate/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The Driver Drowsiness Dataset (DDD) (https://www.kaggle.com/datasets/ismailnasri20/driver-drowsiness-dataset-ddd/) is an extracted and cropped faces of drivers from the videos of the Real-Life Drowsiness Dataset. The frames were extracted from videos as images using VLC software. After that, the Viola-Jones algorithm has been used to extract the region of interest from captured images. The dataset on Kaggle has following properties\n",
    "\n",
    "The dataset has the following properties :\n",
    "• RGB images\n",
    "• 2 classes (Drowsy & Non Drowsy)\n",
    "• Size of image : 227 x 227\n",
    "• More than 41,790 images in total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_file_count(folder_path):\n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Count the number of files\n",
    "    file_count = len(files)\n",
    "\n",
    "    return file_count\n",
    "\n",
    "# Get the file counts\n",
    "drowsy_count = get_file_count(original_drowsy_dataset_dir)\n",
    "non_drowsy_count = get_file_count(original_nondrowsy_dataset_dir)\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Category': ['Drowsy', 'Non Drowsy'], 'Count': [drowsy_count, non_drowsy_count]})\n",
    "\n",
    "# Display the dataframe\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drowsy folder contains around 22348 files and Non Drowsy folder contains around 19445 files. Upon further analysis it was found that there were multiple images of same person increasing the count in dataset. Also, the data set seemed to have incorrect labeling. Lot of images that seemed Non Drowsy were labeled as Drowsy. \n",
    "\n",
    "Hence, a concious decision was taken to manually label 10 images of each person that distinctly categorized image as drowsy and Non Drowsy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file counts\n",
    "train_drowsy_count = get_file_count(manual_annotation_train_drowsy_dir)\n",
    "train_non_drowsy_count = get_file_count(manual_annotation_train_nondrowsy_dir)\n",
    "\n",
    "test_drosy_count = get_file_count(manual_annotation_test_drowsy_dir)\n",
    "test_nondrowsy_count = get_file_count(manual_annotation_test_nondrowsy_dir)\n",
    "\n",
    "total_drowsy_count = train_drowsy_count + test_drosy_count\n",
    "total_non_drowsy_count = train_non_drowsy_count + test_nondrowsy_count\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Category': ['Drowsy', 'Non Drowsy'], 'Count': [total_drowsy_count, total_non_drowsy_count]})\n",
    "\n",
    "# Display the dataframe\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comprehensive dataset comprising 510 images underwent manual annotation. These images are designated for training, validation, and testing purposes. They are to be divided into respective subsets for training, validation, and testing, adhering to a proportional allocation of 60%, 20%, and 20%. Given the nature of the labeling process, which involved approximately 10 images per individual, there exists a potential overlap wherein the test subset might include images of individuals previously encountered during the model's training phase. To address this and to assess the model's performance with previously unseen data, a distinct set of images, specifically those featuring individuals whose names commence with letters S through Z, has been segregated. This measure is intended to evaluate the model's generalization capabilities on novel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drowsy Annotated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the directory path\n",
    "directory = manual_annotation_train_drowsy_dir\n",
    "\n",
    "# Get the list of image files in the directory\n",
    "image_files = os.listdir(directory)\n",
    "\n",
    "# Create a figure with a grid of 1x4 subplots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "# Loop through the first 4 image files\n",
    "for i in range(4):\n",
    "    # Get the image file path\n",
    "    image_file = os.path.join(directory, image_files[i])\n",
    "    \n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    # Display the image in the corresponding subplot\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "    # Display the label above the image\n",
    "    axs[i].set_title('Drowsy', fontsize=10, pad=2)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Drowsy Annotated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "directory = manual_annotation_train_nondrowsy_dir\n",
    "\n",
    "# Get the list of image files in the directory\n",
    "image_files = os.listdir(directory)\n",
    "\n",
    "# Create a figure with a grid of 1x4 subplots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "# Loop through the first 4 image files\n",
    "for i in range(4):\n",
    "    # Get the image file path\n",
    "    image_file = os.path.join(directory, image_files[i])\n",
    "    \n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    # Display the image in the corresponding subplot\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "    # Display the label above the image\n",
    "    axs[i].set_title('Non Drowsy', fontsize=10, pad=2)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess images\n",
    "The preprocessing of the image dataset will be executed through a two-stage process. Initially, the first stage will involve the random selection of 150 images each from directories labeled 'Drowsy' and 'NonDrowsy'. Selecting equal images would balance our dataset. In this phase, images from the 'Drowsy' directory will be annotated with a label of 1, while those from the 'NonDrowsy' directory will receive a label of 0, thus facilitating binary classification.\n",
    "\n",
    "Subsequently, the second stage of preprocessing will focus on standardizing the dimensions of the images to a uniform size of 80x80 pixels. The data is split in training, validation and test set in this step. Additionally, this stage will incorporate various image augmentation techniques, including the adjustment of brightness and contrast, as well as the horizontal flipping of images. These augmented images will then be systematically incorporated into the training dataset, thereby enriching it and potentially enhancing the robustness of the model by exposing it to a more diverse range of data variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_step1(train_dir, num_images=150):\n",
    "    # create empty lists to store the images and their labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # loop through each subdirectory\n",
    "    for subdir in os.listdir(train_dir):\n",
    "        path = os.path.join(train_dir, subdir)\n",
    "        print(path)\n",
    "        if os.path.isdir(path):\n",
    "\n",
    "            # get a list of all the image files in the subdirectory\n",
    "            image_files = os.listdir(path)\n",
    "\n",
    "            # randomly select num_images images from the list\n",
    "            selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "            # loop through the selected images\n",
    "            for image_file in selected_images:\n",
    "                # load the image using load_img               \n",
    "                img = load_img(os.path.join(path, image_file), target_size=(80, 80))\n",
    "\n",
    "                # convert the image to an array using img_to_array\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # append the image and its label to the lists\n",
    "                images.append(img_array)\n",
    "                \n",
    "                if subdir == \"Drowsy\":\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "    # convert the images and labels to numpy arrays\n",
    "    images = np.stack(images)\n",
    "    labels = np.array(labels).flatten()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_step2(images, y, split=(0.6,0.2,0.2), IMAGE_SIZE=(80,80), CONTRAST_FACTOR=3, DELTA=0.3):\n",
    " \n",
    "    ### create train/validation/test sets ###\n",
    "    #########################################\n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1235)\n",
    "    np.random.seed(1235)\n",
    "    shuffle = np.random.permutation(np.arange(images.shape[0]))\n",
    "    images, y = images[shuffle], y[shuffle]\n",
    "    \n",
    "    splits = np.multiply(len(images), split).astype(int)\n",
    "    X_train, X_val, X_test = np.split(images, [splits[0], splits[0]+splits[1]])\n",
    "    y_train, y_val, y_test = np.split(y, [splits[0], splits[0]+splits[1]])\n",
    "    \n",
    "    ### image transformation on training, validation, and test data ###\n",
    "    ###################################################################\n",
    "    # image resize\n",
    "    X_train = tf.image.resize(X_train, size=IMAGE_SIZE)\n",
    "    X_val = tf.image.resize(X_val, size=IMAGE_SIZE)\n",
    "    X_test = tf.image.resize(X_test, size=IMAGE_SIZE)\n",
    "    \n",
    "    # rescale image to [0,1], i.e., greyscale\n",
    "    X_train = X_train/255.0\n",
    "    X_val = X_val/255.0\n",
    "    X_test = X_test/255.0\n",
    "     \n",
    "    ### image augmentation on training data ###\n",
    "    ###########################################\n",
    "    # adjust brightness\n",
    "    X_train_augm = tf.image.adjust_brightness(X_train, delta=DELTA)\n",
    "    \n",
    "    # adjust contrast\n",
    "    X_train_augm = tf.image.adjust_contrast(X_train_augm, contrast_factor=CONTRAST_FACTOR)\n",
    "\n",
    "    # random flip\n",
    "    X_train_augm = tf.image.random_flip_left_right(X_train_augm)\n",
    "    \n",
    "    # concatenate original X_train and augmented X_train data\n",
    "    X_train = tf.concat([X_train, X_train_augm],axis=0)\n",
    "    \n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = y_train\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "    \n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle)\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() #also transforms y_train to numpy array\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_dir):\n",
    "    # Preprocess step 1: Randomly select 150 images from \n",
    "    # the train directory and convert them to arrays\n",
    "    images, y = data_preprocess_step1(train_dir, num_images=150)\n",
    "\n",
    "    # Preprocess step 2: Split the data into training, validation, and test sets\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data_step2(\n",
    "        images, y, split=(0.6,0.2,0.2), IMAGE_SIZE=(80,80), CONTRAST_FACTOR=3, DELTA=0.3)\n",
    "\n",
    "    print(f\"images shape {images.shape}\")\n",
    "    print(f\"y shape {y.shape}\")\n",
    "    print(f\"X_train shape {X_train.shape}\")\n",
    "    print(f\"y_train shape {y_train.shape}\")\n",
    "    print(f\"X_val shape {X_val.shape}\")\n",
    "    print(f\"y_val shape {y_val.shape}\")\n",
    "    print(f\"X_test shape {X_test.shape}\")\n",
    "    print(f\"y_test shape {y_test.shape}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modelV2():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2), name='pool_2')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=256,\n",
    "        name='fc_1', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=128,\n",
    "        name='fc_2', \n",
    "        activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=64,\n",
    "        name='fc_3', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='fc_4',\n",
    "        activation=None))\n",
    "    \n",
    "    # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_modelV2()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline_accuracy(IMAGE_SIZE=(80,80)):\n",
    "    tf.random.set_seed(1235)\n",
    "    np.random.seed(1235)\n",
    "\n",
    "    image_test, label_test = data_preprocess_step1('./data/manual_annotate/test', num_images=50)\n",
    "\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "    image_test = tf.image.resize(image_test, size=IMAGE_SIZE)\n",
    "\n",
    "    image_test = image_test/255.0\n",
    "\n",
    "    test_results = model.evaluate(image_test, label_test)\n",
    "    print('\\nBaseline Test Acc. {:.2f}%'.format(test_results[1]*100))\n",
    "\n",
    "test_baseline_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "x_arr = np.arange(len(hist['loss'])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(X_test, y_test)\n",
    "print('\\nTest Acc. {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1235)\n",
    "np.random.seed(1235)\n",
    "\n",
    "IMAGE_SIZE=(80,80)\n",
    "\n",
    "image_test, label_test = data_preprocess_step1('./data/manual_annotate/test/', num_images=50)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "image_test = tf.image.resize(image_test, size=IMAGE_SIZE)\n",
    "\n",
    "image_test = image_test/255.0\n",
    "\n",
    "test_results = model.evaluate(image_test, label_test)\n",
    "print('\\nTest Acc. {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_build_train_test(train_dir, test_dir):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:08.568275Z",
     "start_time": "2023-11-24T22:59:08.559291Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# create a dictionary to store the number of files in each subdirectory\n",
    "num_files = {}\n",
    "for subdir in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir, subdir)\n",
    "    if os.path.isdir(path):\n",
    "        num_files[subdir] = len(os.listdir(path))\n",
    "\n",
    "# create a pandas dataframe to display the results in a table\n",
    "df = pd.DataFrame.from_dict(num_files, orient='index', columns=['Number of Files'])\n",
    "df.index.name = 'Subdirectory'\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly pick 100 images from each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.079804Z",
     "start_time": "2023-11-24T22:59:09.357904Z"
    }
   },
   "outputs": [],
   "source": [
    "# print taining data\n",
    "print('Print training data examples:')\n",
    "nrows, ncols = 1,4 #print first 4 images\n",
    "f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
    "for i in range(ncols):\n",
    "    axs[i].imshow(array_to_img(X_train[i]))\n",
    "    axs[i].set(title=y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.322715Z",
     "start_time": "2023-11-24T22:59:09.892512Z"
    }
   },
   "outputs": [],
   "source": [
    "# print test data\n",
    "print('Print validation data examples:')\n",
    "nrows, ncols = 1,4 #print first 4 images\n",
    "f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
    "for i in range(ncols):\n",
    "    axs[i].imshow(array_to_img(X_val[i]))\n",
    "    axs[i].set(title=y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.327428Z",
     "start_time": "2023-11-24T22:59:10.325385Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_modelV1():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2), name='pool_2')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1024,\n",
    "        name='fc_1', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='fc_2',\n",
    "        activation=None))\n",
    "    \n",
    "    # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:54.529808Z",
     "start_time": "2023-11-24T22:59:54.483585Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_modelV2():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2), name='pool_2')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=256,\n",
    "        name='fc_1', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=128,\n",
    "        name='fc_2', \n",
    "        activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=64,\n",
    "        name='fc_3', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='fc_4',\n",
    "        activation=None))\n",
    "    \n",
    "    # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modelV3():\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Adding first three convolutional layers\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu', # activation function \n",
    "                    input_shape = (80,80,3) # shape of input (image)\n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "\n",
    "    # Adding pooling after convolutional layers\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2))) # Dimensions of the region that you are pooling\n",
    "\n",
    "    # Adding second set of convolutional layers\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "\n",
    "    # Add last pooling layer.\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Adding first dense layer with 256 nodes\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "    # Adding a dropout layer to avoid overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3)) \n",
    "\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    # adding output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation = None))\n",
    "\n",
    "        # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:58.349082Z",
     "start_time": "2023-11-24T22:59:58.183125Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = build_modelV2()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "              metrics=['accuracy']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1235)\n",
    "np.random.seed(1235)\n",
    "\n",
    "image_test, label_test = data_preprocess_step1('./data/test_cropped_1/', num_images=50)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "test_results = model.evaluate(image_test, label_test)\n",
    "print('\\nBaseline Test Acc. {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:00:25.899747Z",
     "start_time": "2023-11-24T23:00:19.748611Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:00:41.649474Z",
     "start_time": "2023-11-24T23:00:41.391696Z"
    }
   },
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "x_arr = np.arange(len(hist['loss'])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:00:49.852645Z",
     "start_time": "2023-11-24T23:00:49.789270Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results = model.evaluate(X_test, y_test)\n",
    "print('\\nTest Acc. {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:01:00.523936Z",
     "start_time": "2023-11-24T23:01:00.351350Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_tensor = np.expand_dims(X_train[2], axis = 0)\n",
    "\n",
    "# Print image tensor shape\n",
    "print('Shape of image:', img_tensor.shape)\n",
    "  \n",
    "# Print image\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.title('label:' + str(y_train[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs of the first 4 layers, which include conv2D and max pooling layers\n",
    "layer_outputs = [layer.output for layer in model.layers[:4]]\n",
    "activation_model = models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "# grab layer names\n",
    "layer_names = []\n",
    "for layer in model.layers[:4]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "# getting activations of each layer\n",
    "for idx, layer in enumerate(activations):\n",
    "    if idx in (0,1,2,3):\n",
    "        print('----------------')\n",
    "        print('Geeting activations of layer',  idx+1, ':', layer_names[idx])\n",
    "        activation = layer\n",
    "\n",
    "        # shape of layer activation\n",
    "        print('Images size is', activation.shape[1], 'x', activation.shape[2])\n",
    "        print('Number of channels is', activation.shape[3])\n",
    "\n",
    "        # print channels\n",
    "        print('Printing channels:')\n",
    "        \n",
    "        # define nrows and ncols depending on number of channels\n",
    "        if idx in (0,1):\n",
    "            nrows, ncols = 4,8\n",
    "        if idx in (2,3):\n",
    "            nrows, ncols = 8,8\n",
    "\n",
    "        # plots\n",
    "        channel=0\n",
    "        if idx in (0,1):\n",
    "            f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
    "        if idx in (2,3):\n",
    "            f, axs = plt.subplots(nrows, ncols, figsize=(16,20))\n",
    "            \n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                if i==0 and j==0:\n",
    "                    channel=0\n",
    "                else:\n",
    "                    channel+=1\n",
    "\n",
    "                im = axs[i,j].matshow(activation[0,:, :, channel], cmap ='viridis')\n",
    "                axs[i,j].set(title=str(channel))\n",
    "                plt.colorbar(im, ax=axs[i, j], fraction=0.046, pad=0.04)\n",
    "                #axs[i,j].axis('off') # pay attention to the range of x and y axis\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:02:50.438036Z",
     "start_time": "2023-11-24T23:02:50.249488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1235)\n",
    "np.random.seed(1235)\n",
    "\n",
    "IMAGE_SIZE=(80,80)\n",
    "\n",
    "image_test, label_test = data_preprocess_step1('./data/test_cropped_1/', num_images=50)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "image_test = tf.image.resize(image_test, size=IMAGE_SIZE)\n",
    "\n",
    "image_test = image_test/255.0\n",
    "\n",
    "test_results = model.evaluate(image_test, label_test)\n",
    "print('\\nTest Acc. {:.2f}%'.format(test_results[1]*100))\n",
    "\n",
    "#print(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = model.predict(image_test)\n",
    "probas = tf.sigmoid(pred_logits)\n",
    "probas = probas.numpy().flatten()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 50))\n",
    "\n",
    "for j, example in enumerate(image_test):\n",
    "    ax = fig.add_subplot(int(len(label_test)/4),4, j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(array_to_img(example))\n",
    "    if label_test[j]==0:\n",
    "        label='Non Drowsy'\n",
    "    else:\n",
    "        label='Drowsy'\n",
    "    \n",
    "    ax.text(\n",
    "        0.5, -0.15, \n",
    "        'GT: {:s}\\nPr(Drowsy)={:.0f}%'.format(label, probas[j]), \n",
    "        size=10, \n",
    "        color='black',\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:03:37.334475Z",
     "start_time": "2023-11-24T23:03:34.898451Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "def predict(model, img):\n",
    "    img= keras.utils.load_img(\n",
    "        img, target_size=(80, 80))\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "dir_path = \"./data/test_cropped/Drowsy/\"\n",
    "i = 0\n",
    "file_path = []\n",
    "prediction_results = []\n",
    "for file_name in os.listdir(dir_path):\n",
    "    \n",
    "    predictions = predict(model, dir_path+file_name)\n",
    "    \n",
    "    print (predictions)\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    probabilities = tf.nn.sigmoid(predictions).numpy()\n",
    "    \n",
    "    prediction_results.append(probabilities[0])\n",
    "    file_path.append(dir_path+file_name)\n",
    "\n",
    "\n",
    "\n",
    "data = {'file_path': file_path, 'prediction_results': prediction_results}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "'''\n",
    "# Display the dataframe with filepath as a link to the image\n",
    "for index, row in df.iterrows():\n",
    "    display(Image(filename=row['file_path']))\n",
    "    print(row)\n",
    "'''\n",
    "\n",
    "    \n",
    "\n",
    "# Define the grid size based on the number of images\n",
    "num_images = len(df)\n",
    "grid_size = int(num_images ** 0.5) + 1\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axs = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "\n",
    "# Iterate over the dataframe rows and display the image with prediction result\n",
    "for index, row in df.iterrows():\n",
    "    img = plt.imread(row['file_path'])\n",
    "    ax = axs[index // grid_size, index % grid_size]\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Prediction: {row['prediction_results']:.2f}\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(num_images, grid_size ** 2):\n",
    "    axs[i // grid_size, i % grid_size].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(np.array(prediction_results))\n",
    "array = np.array(prediction_results)\n",
    "print(np.size(array))\n",
    "\n",
    "um_elements_greater_than_zero = np.sum(array > 0)\n",
    "\n",
    "print (um_elements_greater_than_zero)\n",
    "\n",
    "um_elements_less_than_zero = np.sum(array < 0)\n",
    "print (um_elements_less_than_zero)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
