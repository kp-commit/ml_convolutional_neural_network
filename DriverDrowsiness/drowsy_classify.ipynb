{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:08.558304Z",
     "start_time": "2023-11-24T22:59:05.339050Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_drowsy_dataset_dir = './data/original_dataset/Drowsy'\n",
    "original_nondrowsy_dataset_dir = './data/original_dataset/NonDrowsy'\n",
    "manual_annotation_train_drowsy_dir = './data/manual_annotate/train/Drowsy'\n",
    "manual_annotation_train_nondrowsy_dir = './data/manual_annotate/train/NonDrowsy'\n",
    "manual_annotation_test_drowsy_dir = './data/manual_annotate/test/Drowsy'\n",
    "manual_annotation_test_nondrowsy_dir = './data/manual_annotate/test/NonDrowsy'\n",
    "manual_annotation_nondrowsy_dir = './data/manual_annotate/NonDrowsy'\n",
    "train_dir = './data/manual_annotate/train80'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "The Driver Drowsiness Dataset (DDD) (https://www.kaggle.com/datasets/ismailnasri20/driver-drowsiness-dataset-ddd/) is an extracted and cropped faces of drivers from the videos of the Real-Life Drowsiness Dataset. The frames were extracted from videos as images using VLC software. After that, the Viola-Jones algorithm has been used to extract the region of interest from captured images. The dataset on Kaggle has following properties\n",
    "\n",
    "The dataset has the following properties :\n",
    "• RGB images\n",
    "• 2 classes (Drowsy & Non Drowsy)\n",
    "• Size of image : 227 x 227\n",
    "• More than 41,790 images in total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_count(folder_path):\n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Count the number of files\n",
    "    file_count = len(files)\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the file counts\n",
    "drowsy_count = get_file_count(original_drowsy_dataset_dir)\n",
    "non_drowsy_count = get_file_count(original_nondrowsy_dataset_dir)\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Category': ['Drowsy', 'Non Drowsy'], 'Count': [drowsy_count, non_drowsy_count]})\n",
    "\n",
    "# Display the dataframe\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drowsy folder contains around 22348 files and Non Drowsy folder contains around 19445 files. Upon further analysis it was found that there were multiple images of same person increasing the count in dataset. Also, the data set seemed to have incorrect labeling. Lot of images that seemed Non Drowsy were labeled as Drowsy. \n",
    "\n",
    "Hence, a concious decision was taken to manually label 10 images of each person that distinctly categorized image as drowsy and Non Drowsy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file counts\n",
    "train_drowsy_count = get_file_count(manual_annotation_train_drowsy_dir)\n",
    "train_non_drowsy_count = get_file_count(manual_annotation_train_nondrowsy_dir)\n",
    "\n",
    "\n",
    "test_drosy_count = get_file_count(manual_annotation_test_drowsy_dir)\n",
    "test_nondrowsy_count = get_file_count(manual_annotation_test_nondrowsy_dir)\n",
    "\n",
    "total_drowsy_count = train_drowsy_count + test_drosy_count\n",
    "total_non_drowsy_count = train_non_drowsy_count + test_nondrowsy_count\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Category': ['Drowsy', 'Non Drowsy'], 'Count': [total_drowsy_count, total_non_drowsy_count]})\n",
    "\n",
    "# Display the dataframe\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comprehensive dataset comprising 510 images underwent manual annotation. These images are designated for training, validation, and testing purposes. They are to be divided into respective subsets for training, validation, and testing, adhering to a proportional allocation of 60%, 20%, and 20%. Given the nature of the labeling process, which involved approximately 10 images per individual, there exists a potential overlap wherein the test subset might include images of individuals previously encountered during the model's training phase. To address this and to assess the model's performance with previously unseen data, a distinct set of images, specifically those featuring individuals whose names commence with letters S through Z, has been segregated. This measure is intended to evaluate the model's generalization capabilities on novel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drowsy Annotated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(directory, title):\n",
    "\n",
    "    # Get the list of image files in the directory\n",
    "    image_files = os.listdir(directory)\n",
    "\n",
    "    # Create a figure with a grid of 1x4 subplots\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "    # Loop through the first 4 image files\n",
    "    for i in range(4):\n",
    "        # Get the image file path\n",
    "        image_file = os.path.join(directory, image_files[i])\n",
    "        \n",
    "        # Open the image using PIL\n",
    "        image = Image.open(image_file)\n",
    "        \n",
    "        # Display the image in the corresponding subplot\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('on')\n",
    "        \n",
    "        # Display the label above the image\n",
    "        axs[i].set_title(title, fontsize=10, pad=2)\n",
    "        \n",
    "        # Add grid lines to the subplot\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "plot_images(directory = manual_annotation_train_drowsy_dir, title = 'Drowsy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Drowsy Annotated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(directory = manual_annotation_train_nondrowsy_dir, title = 'Non Drowsy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "The preprocessing of the image dataset will be executed through a two-stage process. Initially, the first stage will involve the random selection of 150 images each from directories labeled 'Drowsy' and 'NonDrowsy'. Selecting equal images would balance our dataset. In this phase, images from the 'Drowsy' directory will be annotated with a label of 1, while those from the 'NonDrowsy' directory will receive a label of 0, thus facilitating binary classification.\n",
    "\n",
    "Subsequently, the second stage of preprocessing will focus on standardizing the dimensions of the images to a uniform size of 80x80 pixels. The data is split in training, validation and test set in this step. Additionally, this stage will incorporate various image augmentation techniques, including the adjustment of brightness and contrast, as well as the horizontal flipping of images. These augmented images will then be systematically incorporated into the training dataset, thereby enriching it and potentially enhancing the robustness of the model by exposing it to a more diverse range of data variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_step1(train_dir, num_images=150):\n",
    "    # create empty lists to store the images and their labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # loop through each subdirectory\n",
    "    for subdir in os.listdir(train_dir):\n",
    "        path = os.path.join(train_dir, subdir)\n",
    "        print(path)\n",
    "        if os.path.isdir(path):\n",
    "\n",
    "            # get a list of all the image files in the subdirectory\n",
    "            image_files = os.listdir(path)\n",
    "\n",
    "            # randomly select num_images images from the list\n",
    "            random.seed(12356)\n",
    "            np.random.seed(12356)\n",
    "            selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "            # loop through the selected images\n",
    "            for image_file in selected_images:\n",
    "                # load the image using load_img               \n",
    "                img = load_img(os.path.join(path, image_file), target_size=(80, 80))\n",
    "\n",
    "                # convert the image to an array using img_to_array\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # append the image and its label to the lists\n",
    "                images.append(img_array)\n",
    "                \n",
    "                if subdir == \"Drowsy\":\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "    # convert the images and labels to numpy arrays\n",
    "    images = np.stack(images)\n",
    "    labels = np.array(labels).flatten()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_step2(images, y, split=(0.8,0.2), IMAGE_SIZE=(80,80), CONTRAST_FACTOR=3, DELTA=0.3, normalize=True):\n",
    " \n",
    "    ### create train/validation/test sets ###\n",
    "    #########################################\n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1235)\n",
    "    np.random.seed(1235)\n",
    "    shuffle = np.random.permutation(np.arange(images.shape[0]))\n",
    "    images, y = images[shuffle], y[shuffle]\n",
    "    \n",
    "    splits = np.multiply(len(images), split).astype(int)\n",
    "    X_train, X_val = np.split(images, [splits[0]])\n",
    "    y_train, y_val = np.split(y, [splits[0]])\n",
    "    \n",
    "    ### image transformation on training, validation, and test data ###\n",
    "    ###################################################################\n",
    "    # image resize\n",
    "    X_train = tf.image.resize(X_train, size=IMAGE_SIZE)\n",
    "    X_val = tf.image.resize(X_val, size=IMAGE_SIZE)\n",
    "\n",
    "    \n",
    "    # rescale image to [0,1], i.e., greyscale\n",
    "    if normalize:\n",
    "        X_train = X_train/255.0\n",
    "        X_val = X_val/255.0\n",
    "\n",
    "     \n",
    "    ### image augmentation on training data ###\n",
    "    ###########################################\n",
    "    # adjust brightness\n",
    "    X_train_augm = tf.image.adjust_brightness(X_train, delta=DELTA)\n",
    "    \n",
    "    # adjust contrast\n",
    "    X_train_augm = tf.image.adjust_contrast(X_train_augm, contrast_factor=CONTRAST_FACTOR)\n",
    "\n",
    "    # random flip\n",
    "    X_train_augm = tf.image.random_flip_left_right(X_train_augm)\n",
    "\n",
    "    #X_train_augm = tfa.image.rotate(X_train_augm, np.random.uniform(-30, 30))\n",
    "    \n",
    "    # concatenate original X_train and augmented X_train data\n",
    "    X_train = tf.concat([X_train, X_train_augm],axis=0)\n",
    "    \n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = y_train\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "    \n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle)\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() #also transforms y_train to numpy array\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_dir, normalize=True):\n",
    "    # Preprocess step 1: Randomly select 150 images from \n",
    "    # the train directory and convert them to arrays\n",
    "    images, y = data_preprocess_step1(train_dir, num_images=150)\n",
    "\n",
    "    # Preprocess step 2: Split the data into training, validation, and test sets\n",
    "    X_train, y_train, X_val, y_val= preprocess_data_step2(\n",
    "        images, y, split=(0.8,0.2), IMAGE_SIZE=(80,80), CONTRAST_FACTOR=3, DELTA=0.3, normalize=normalize)\n",
    "\n",
    "    print('\\n----------Preprocessing Summary----------')\n",
    "    print(f\"images shape {images.shape}\")\n",
    "    print(f\"y shape {y.shape}\")\n",
    "    print(f\"X_train shape {X_train.shape}\")\n",
    "    print(f\"y_train shape {y_train.shape}\")\n",
    "    print(f\"X_val shape {X_val.shape}\")\n",
    "    print(f\"y_val shape {y_val.shape}\")\n",
    "\n",
    "    print\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "Describe model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function builds a dynamic model for classifying drowsiness in drivers.\n",
    "# It takes in various parameters to customize the architecture of the model.\n",
    "def build_model_dynamic(num_conv = 2, \n",
    "                        filters = [16,16], \n",
    "                        kernel_size = [(5,5),(5,5)], \n",
    "                        strides = [(1,1),(1,1)], \n",
    "                        pool_size = [(2,2),(2,2)], \n",
    "                        pool_names = ['pool_1', 'pool_2'], \n",
    "                        conv_dropout_rate= [0.3,0.5], \n",
    "                        fc_dropout_rate = [0.5, 0, 0],\n",
    "                        conv_batch_normalization = [True, True], \n",
    "                        fc_batch_normalization = [False, True, True],\n",
    "                        activations = ['relu', 'relu', 'relu', 'relu', 'relu'], \n",
    "                        num_dense = 3, units = [128, 64, 32], \n",
    "                        conv_layer_names = ['conv_1', 'conv_2'],\n",
    "                        fc_layer_names =['fc_1', 'fc_2', 'fc_3', 'output']):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Loop through the specified number of convolutional layers\n",
    "    for _ in range(num_conv):\n",
    "        # Add a convolutional layer with the specified parameters\n",
    "        model.add(layers.Conv2D(filters[_], \n",
    "                                kernel_size=kernel_size[_], \n",
    "                                strides=strides[_],\n",
    "                                padding='same',\n",
    "                                data_format='channels_last',\n",
    "                                name=conv_layer_names[_]))\n",
    "        \n",
    "        # Add batch normalization if specified\n",
    "        if conv_batch_normalization[_]:\n",
    "            model.add(layers.BatchNormalization())\n",
    "\n",
    "        # Add the specified activation function\n",
    "        model.add(layers.Activation(activations[_]))\n",
    "        \n",
    "        if conv_dropout_rate[_] != 0:\n",
    "            # Add dropout layer with the specified dropout rate\n",
    "            model.add(layers.Dropout(conv_dropout_rate[_]))\n",
    "\n",
    "        # Add max pooling layer with the specified pool size\n",
    "        model.add(layers.MaxPooling2D(pool_size=pool_size[_], name=pool_names[_]))\n",
    "\n",
    "\n",
    "\n",
    "    # Flatten the output of the convolutional layers\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Loop through the specified number of dense layers\n",
    "    for _ in range(num_dense):\n",
    "        # Add a dense layer with the specified number of units\n",
    "        model.add(layers.Dense(units[_], name=fc_layer_names[_]))\n",
    "\n",
    "        # Add batch normalization if specified\n",
    "        if fc_batch_normalization[_]:\n",
    "            model.add(layers.BatchNormalization())\n",
    "            \n",
    "        # Add the specified activation function\n",
    "        model.add(layers.Activation(activations[_]))\n",
    "\n",
    "        if fc_dropout_rate[_] != 0:\n",
    "            # Add dropout layer with the specified dropout rate\n",
    "            model.add(layers.Dropout(fc_dropout_rate[_]))\n",
    "\n",
    "    # Add the final dense layer with 1 unit for binary classification\n",
    "    model.add(layers.Dense(1, activation=None, name=fc_layer_names[-1]))\n",
    "\n",
    "    # Set the random seed and build the model with the specified input shape\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modelV2():\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1'))\n",
    "    \n",
    "    # Add Batch Normalization layer\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # Add the activation layer separately\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.3))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        name='conv_2'))\n",
    "    \n",
    "    # Add Batch Normalization layer\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # Add the activation layer separately\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "    \n",
    "    \n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2), name='pool_2')\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=128,\n",
    "        name='fc_1', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=64,\n",
    "        name='fc_2'\n",
    "    ))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=32,\n",
    "        name='fc_3'\n",
    "        ))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='fc_4',\n",
    "        activation=None))\n",
    "    \n",
    "    # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_optimizer(learning_rate=0.001, optimizer='adam'):\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer specified.\")\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def build_model(learning_rate=0.001, optimizer='adam'):   \n",
    "    model = build_modelV2()\n",
    "    model.summary()\n",
    "    optimizer = build_optimizer(learning_rate, optimizer)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_dyn(    learning_rate=0.001, \n",
    "                        optimizer='adam', \n",
    "                        num_conv = 2, \n",
    "                        filters = [16,16], \n",
    "                        kernel_size = [(5,5),(5,5)], \n",
    "                        strides = [(1,1),(1,1)], \n",
    "                        pool_size = [(2,2),(2,2)], \n",
    "                        pool_names = ['pool_1', 'pool_2'], \n",
    "                        conv_dropout_rate= [0.3, 0.5], \n",
    "                        fc_dropout_rate = [0.5, 0, 0],\n",
    "                        conv_batch_normalization = [True, True], \n",
    "                        fc_batch_normalization = [False, True, True],\n",
    "                        activations = ['relu', 'relu', 'relu', 'relu', 'relu'], \n",
    "                        num_dense = 3, \n",
    "                        units = [128, 64, 32], \n",
    "                        conv_layer_names = ['conv_1', 'conv_2'],\n",
    "                        fc_layer_names =['fc_1', 'fc_2', 'fc_3', 'output']):  \n",
    "     \n",
    "    model = build_model_dynamic(\n",
    "                                num_conv=num_conv,\n",
    "                                filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                strides=strides,\n",
    "                                pool_size=pool_size,\n",
    "                                pool_names=pool_names,\n",
    "                                conv_dropout_rate=conv_dropout_rate,\n",
    "                                fc_dropout_rate=fc_dropout_rate,\n",
    "                                conv_batch_normalization=conv_batch_normalization,\n",
    "                                fc_batch_normalization=fc_batch_normalization,\n",
    "                                activations=activations,\n",
    "                                num_dense=num_dense,\n",
    "                                units=units,\n",
    "                                conv_layer_names=conv_layer_names,\n",
    "                                fc_layer_names=fc_layer_names)\n",
    "    \n",
    "    model.summary()\n",
    "    optimizer = build_optimizer(learning_rate, optimizer)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline_accuracy(model, test_dir, IMAGE_SIZE=(80,80), normalize=True):\n",
    "    tf.random.set_seed(1235)\n",
    "    np.random.seed(1235)\n",
    "\n",
    "    image_test, label_test = data_preprocess_step1(test_dir, num_images=50)\n",
    "\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "    image_test = tf.image.resize(image_test, size=IMAGE_SIZE)\n",
    "\n",
    "    if normalize:\n",
    "        image_test = image_test/255.0\n",
    "\n",
    "    test_results = model.evaluate(image_test, label_test)\n",
    "\n",
    "    print('\\n----------Baseline Model Test Results----------')\n",
    "    print('\\nBaseline Test Acc. {:.2f}%'.format(test_results[1]*100))\n",
    "    print('-----------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, y_train, X_val, y_val, epochs=20):\n",
    "    tf.random.set_seed(6666)\n",
    "    np.random.seed(6666)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs, \n",
    "                        validation_data=(X_val, y_val)\n",
    "                        #callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, history_plot_file = './plots/history_plot.png'):\n",
    "    \n",
    "    hist = history.history\n",
    "    x_arr = np.arange(len(hist['loss'])) + 1\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "    ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n",
    "    ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Accuracy', size=15)\n",
    "    plt.show()\n",
    "\n",
    "    if history_plot_file != None:     \n",
    "        fig.savefig(history_plot_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dir, normalize = True):\n",
    "\n",
    "    tf.random.set_seed(1235)\n",
    "    np.random.seed(1235)\n",
    "\n",
    "    IMAGE_SIZE=(80,80)\n",
    "\n",
    "    image_test, label_test = data_preprocess_step1(test_dir + '/', num_images=50)\n",
    "\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "\n",
    "    image_test = tf.image.resize(image_test, size=IMAGE_SIZE)\n",
    "\n",
    "    if normalize:\n",
    "        image_test = image_test/255.0\n",
    "\n",
    "    test_results = model.evaluate(image_test, label_test)\n",
    "    print('\\n----------Model Test Accuracy Results----------')\n",
    "    print('\\nTest Acc. {:.2f}%'.format(test_results[1]*100))\n",
    "    print('-----------------------------------------------')\n",
    "\n",
    "    return test_results[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_build_train_test(train_dir, \n",
    "                                test_dir, \n",
    "                                normalize=True, \n",
    "                                learning_rate=0.001, \n",
    "                                optimizer='adam',\n",
    "                                epochs=20,\n",
    "                                num_conv = 2, \n",
    "                                filters = [16,16], \n",
    "                                kernel_size = [(5,5),(5,5)], \n",
    "                                strides = [(1,1),(1,1)], \n",
    "                                pool_size = [(2,2),(2,2)], \n",
    "                                pool_names = ['pool_1', 'pool_2'], \n",
    "                                conv_dropout_rate= [0.3, 0.5], \n",
    "                                fc_dropout_rate = [0.5, 0, 0],\n",
    "                                conv_batch_normalization = [True, True], \n",
    "                                fc_batch_normalization = [False, True, True],\n",
    "                                activations = ['relu', 'relu', 'relu', 'relu', 'relu'], \n",
    "                                num_dense = 3, \n",
    "                                units = [128, 64, 32], \n",
    "                                conv_layer_names = ['conv_1', 'conv_2'],\n",
    "                                fc_layer_names =['fc_1', 'fc_2', 'fc_3', 'output'],\n",
    "                                history_plot_file = './plots/history.png'):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    X_train, y_train, X_val, y_val = preprocess(train_dir, normalize=normalize)\n",
    "\n",
    "    model = build_model_dyn(learning_rate=learning_rate, \n",
    "                            optimizer=optimizer, \n",
    "                            num_conv=num_conv,\n",
    "                            filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=strides,\n",
    "                            pool_size=pool_size,\n",
    "                            pool_names=pool_names,\n",
    "                            conv_dropout_rate=conv_dropout_rate,\n",
    "                            fc_dropout_rate=fc_dropout_rate,\n",
    "                            conv_batch_normalization=conv_batch_normalization,\n",
    "                            fc_batch_normalization=fc_batch_normalization,\n",
    "                            activations=activations,\n",
    "                            num_dense=num_dense,\n",
    "                            units=units,\n",
    "                            conv_layer_names=conv_layer_names,\n",
    "                            fc_layer_names=fc_layer_names\n",
    "                            )\n",
    "    \n",
    "    test_baseline_accuracy(model, test_dir, normalize=normalize)\n",
    "    history = fit_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "    plot_history(history, history_plot_file=history_plot_file)\n",
    "    test_acc = evaluate_model(model, test_dir, normalize=normalize)\n",
    "\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    # Calculate the size of the model\n",
    "    total_model_size = 0\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for weight in layer.weights:\n",
    "            param_size = weight.shape.num_elements() * weight.dtype.size\n",
    "            total_model_size += param_size\n",
    "\n",
    "    total_model_size_kb = total_model_size / 1024\n",
    "    total_model_size_mb = total_model_size_kb / 1024\n",
    "\n",
    "    print(f\"Model size: {total_model_size_kb:.2f} KB or {total_model_size_mb:.2f} MB\")\n",
    "\n",
    "    return total_model_size_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXP = 5\n",
    "\n",
    "learning_rate               =   [0.001,\n",
    "                                 0.001,\n",
    "                                 0.001,\n",
    "                                 0.001,\n",
    "                                 0.001]\n",
    " \n",
    "optimizer                   =   ['adam',\n",
    "                                 'adam', \n",
    "                                 'adam', \n",
    "                                 'adam',\n",
    "                                 'adam']\n",
    "                                 \n",
    "                        \n",
    "filters                     =   [[16,16],\n",
    "                                 [16,16],\n",
    "                                 [16,16], \n",
    "                                 [16,16],\n",
    "                                 [16,16]] \n",
    "\n",
    "kernel_size                 =   [[(5,5),(5,5)], \n",
    "                                 [(3,3),(3,3)], \n",
    "                                 [(3,3), (5,5)], \n",
    "                                 [(5,5), (3,3)],\n",
    "                                 [(5,5),(5,5)]]\n",
    " \n",
    "strides                     =   [[(1,1),(1,1)], \n",
    "                                 [(1,1),(1,1)], \n",
    "                                 [(1,1),(1,1)], \n",
    "                                 [(1,1),(1,1)],\n",
    "                                 [(1,1),(1,1)]]\n",
    "\n",
    "pool_size                   =   [[(2,2),(2,2)],\n",
    "                                 [(2,2),(2,2)],\n",
    "                                 [(2,2),(2,2)], \n",
    "                                 [(2,2),(2,2)],\n",
    "                                 [(2,2),(2,2)]]\n",
    "                        \n",
    "conv_dropout_rate           =   [[0.3, 0.5],\n",
    "                                 [0.3, 0.5], \n",
    "                                 [0.3, 0.5], \n",
    "                                 [0.3, 0.5],\n",
    "                                 [0.3, 0.5]]\n",
    "\n",
    "fc_dropout_rate             =   [[0.5, 0, 0],\n",
    "                                 [0.5, 0, 0], \n",
    "                                 [0.5, 0, 0], \n",
    "                                 [0.5, 0, 0],\n",
    "                                 [0.5, 0, 0]]\n",
    "\n",
    "conv_batch_normalization    =   [[True, True],\n",
    "                                 [True, True], \n",
    "                                 [True, True], \n",
    "                                 [True, True],\n",
    "                                 [True, True]]\n",
    "\n",
    "fc_batch_normalization      =   [[False, True, True],\n",
    "                                 [False, True, True], \n",
    "                                 [False, True, True], \n",
    "                                 [False, True, True],\n",
    "                                 [False, True, True]]\n",
    "\n",
    "activations                 =   [['relu', 'relu', 'relu', 'relu', 'relu'],\n",
    "                                 ['relu', 'relu', 'relu', 'relu', 'relu'],\n",
    "                                 ['relu', 'relu', 'relu', 'relu', 'relu'],\n",
    "                                 ['relu', 'relu', 'relu', 'relu', 'relu'],\n",
    "                                 ['relu', 'relu', 'relu', 'relu', 'relu']]\n",
    "                        \n",
    "units                       =   [[128, 64, 32],\n",
    "                                 [128, 64, 32],\n",
    "                                 [128, 64, 32],\n",
    "                                 [128, 64, 32],\n",
    "                                 [64, 64, 32]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "learning_rate               =   [0.001,\n",
    "                                 0.01]\n",
    " \n",
    "optimizer                   =   ['adam',\n",
    "                                 'adagrad', \n",
    "                                 'sgd']\n",
    "                                 \n",
    "                        \n",
    "filters                     =   [[16,16],\n",
    "                                 [16,8],\n",
    "                                 [8,16], \n",
    "                                 [8,8]] \n",
    "\n",
    "kernel_size                 =   [[(5,5),(5,5)], \n",
    "                                 [(3,3),(3,3)], \n",
    "                                 [(3,3),(5,5)], \n",
    "                                 [(5,5),(3,3)]]\n",
    " \n",
    "strides                     =   [[(1,1),(1,1)], \n",
    "                                 [(2,2),(2,2)]]\n",
    "\n",
    "pool_size                   =   [[(2,2),(2,2)]]\n",
    "                        \n",
    "conv_dropout_rate           =   [[0.3, 0.5]]\n",
    "\n",
    "fc_dropout_rate             =   [[0.5, 0, 0]]\n",
    "\n",
    "conv_batch_normalization    =   [[True, True]]\n",
    "\n",
    "fc_batch_normalization      =   [[False, True, True]]\n",
    "\n",
    "activations                 =   [['relu', 'relu', 'relu', 'relu', 'relu']]\n",
    "                        \n",
    "units                       =   [[128, 64, 32],\n",
    "                                 [64, 64, 32]]\n",
    "\n",
    "epochs                      =   [10, 20, 30, 40]\n",
    "\n",
    "\n",
    "def build_permutations(lists):\n",
    "\n",
    "    # Generate permutations of one element from each list\n",
    "    all_permutations = list(product(*lists))\n",
    "\n",
    "    # Print the permutations\n",
    "    for idx, permutation in enumerate(all_permutations, start=1):\n",
    "        print(f\"Permutation {idx}: {permutation}\")\n",
    "\n",
    "    return all_permutations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "            'Learning Rate': [],\n",
    "            'Filters': [],\n",
    "            'Kernel Size': [],\n",
    "            'Strides': [],\n",
    "            'optimizer': [],\n",
    "            'Conv Dropout Rate': [],\n",
    "            'FC Dropout Rate': [],\n",
    "            'Units': [],\n",
    "            'Pool Size': [],\n",
    "            'Epochs': [],\n",
    "            'Test Accuracy': [],\n",
    "            'Model Size': [],\n",
    "            'History Plot': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory(dir_path):\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def clear_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        files = os.listdir(directory)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output, FileLink\n",
    "import os\n",
    "\n",
    "plot_dir = './plots/full_face/'\n",
    "clear_dir(plot_dir)\n",
    "create_directory(plot_dir)\n",
    "output_file = './data/output_ff.xlsx'\n",
    "\n",
    "model_ff_list = []\n",
    "\n",
    "data['Learning Rate'].clear()\n",
    "data['Filters'].clear()\n",
    "data['Kernel Size'].clear()\n",
    "data['Strides'].clear()\n",
    "data['optimizer'].clear()\n",
    "data['Conv Dropout Rate'].clear()\n",
    "data['FC Dropout Rate'].clear()\n",
    "data['Units'].clear()\n",
    "data['Pool Size'].clear()\n",
    "data['Epochs'].clear()\n",
    "data['Test Accuracy'].clear()\n",
    "data['Model Size'].clear()\n",
    "data['History Plot'].clear()\n",
    "\n",
    "lists = [learning_rate, optimizer, filters, kernel_size, strides, pool_size, conv_dropout_rate, fc_dropout_rate, conv_batch_normalization, fc_batch_normalization, activations, units, epochs]\n",
    "\n",
    "all_permutations = build_permutations(lists)\n",
    "\n",
    "for idx, permutation in enumerate(all_permutations, start=1):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    model, accuracy = preprocess_build_train_test('./data/manual_annotate/train', \n",
    "                                                  './data/manual_annotate/test', \n",
    "                                                  normalize=True, \n",
    "                                                  learning_rate=permutation[0], \n",
    "                                                  optimizer=permutation[1],\n",
    "                                                  epochs=permutation[12]    ,\n",
    "                                                  num_conv = 2, \n",
    "                                                  filters = permutation[2], \n",
    "                                                  kernel_size = permutation[3], \n",
    "                                                  strides = permutation[4], \n",
    "                                                  pool_size = permutation[5], \n",
    "                                                  pool_names = ['pool_1', 'pool_2'], \n",
    "                                                  conv_dropout_rate= permutation[6], \n",
    "                                                  fc_dropout_rate = permutation[7],\n",
    "                                                  conv_batch_normalization = permutation[8], \n",
    "                                                  fc_batch_normalization = permutation[9],\n",
    "                                                  activations = permutation[10], \n",
    "                                                  num_dense = 3, \n",
    "                                                  units = permutation[11], \n",
    "                                                  conv_layer_names = ['conv_1', 'conv_2'],\n",
    "                                                  fc_layer_names =['fc_1', 'fc_2', 'fc_3', 'output'],\n",
    "                                                  history_plot_file=f'{plot_dir}/history_{idx}.png')\n",
    "    \n",
    "    model_ff_list.append(model)\n",
    "\n",
    "                                                    \n",
    "    data['Learning Rate'].append(permutation[0])\n",
    "    data['Filters'].append(permutation[2])\n",
    "    data['Kernel Size'].append(permutation[3])\n",
    "    data['Strides'].append(permutation[4])\n",
    "    data['optimizer'].append(permutation[1])\n",
    "    data['Conv Dropout Rate'].append(permutation[6])\n",
    "    data['FC Dropout Rate'].append(permutation[7])\n",
    "    data['Units'].append(permutation[11])\n",
    "    data['Pool Size'].append(permutation[5])\n",
    "    data['Epochs'].append(permutation[12])\n",
    "    data['Test Accuracy'].append(accuracy)\n",
    "    data['Model Size'].append(get_model_size(model))\n",
    "    data['History Plot'].append(FileLink(f'{plot_dir}/history_{idx}.png'))    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if idx % 5 == 0:\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        \n",
    "        df.to_excel(output_file, index=False)\n",
    "\n",
    "        display(df)\n",
    "        \n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "Despite achieving commendable levels of accuracy in both training and validation phases, the model exhibited suboptimal performance in the testing phase, as evidenced by lower test accuracy. In an effort to ameliorate this discrepancy, a series of methodical adjustments were implemented: augmenting the model architecture with additional convolutional layers, expanding the model complexity by introducing more dense layers, varying the number of filters within convolutional layers, fine-tuning the learning rate, and altering the number of training epochs. Nonetheless, these modifications failed to yield a significant improvement in the model's ability to generalize effectively to the test images.\n",
    "\n",
    "Consequently, we shifted our focus to specifically analyzing the eye region, rather than the entire face, for drowsiness detection. To facilitate this approach, we employed external libraries, namely 'face_recognition' and 'dlib', to precisely extract the eye regions from our annotated image dataset. These cropped eye images were then utilized for the training, validation, and testing phases of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eye Images File Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:08.568275Z",
     "start_time": "2023-11-24T22:59:08.559291Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "eye_train_drowsy = get_file_count('./data/cropped_1/Drowsy')\n",
    "eye_train_nondrowsy = get_file_count('./data/cropped_1/NonDrowsy')\n",
    "eye_test_drowsy = get_file_count('./data/test_cropped_1/Drowsy')\n",
    "eye_test_nondrowsy = get_file_count('./data/test_cropped_1/NonDrowsy')\n",
    "\n",
    "eye_drowsy_count = eye_test_drowsy + eye_train_drowsy \n",
    "eye_nondrowsy_count = eye_test_nondrowsy + eye_train_nondrowsy\n",
    "\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Category': ['Drowsy', 'Non Drowsy'], 'Count': [eye_drowsy_count, eye_nondrowsy_count]})\n",
    "\n",
    "# Display the dataframe\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drowsy Eye Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.079804Z",
     "start_time": "2023-11-24T22:59:09.357904Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_images(directory = './data/cropped_1/Drowsy', title = 'Drowsy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Drowsy Eye Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.322715Z",
     "start_time": "2023-11-24T22:59:09.892512Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_images(directory = './data/cropped_1/NonDrowsy', title = 'Non Drowsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, FileLink\n",
    "import os\n",
    "\n",
    "plot_dir = './plots/eye/'\n",
    "clear_dir(plot_dir)\n",
    "create_directory(plot_dir)\n",
    "output_file = './data/output_eye.xlsx'\n",
    "\n",
    "model_ff_list = []\n",
    "\n",
    "data['Learning Rate'].clear()\n",
    "data['Filters'].clear()\n",
    "data['Kernel Size'].clear()\n",
    "data['Strides'].clear()\n",
    "data['optimizer'].clear()\n",
    "data['Conv Dropout Rate'].clear()\n",
    "data['FC Dropout Rate'].clear()\n",
    "data['Units'].clear()\n",
    "data['Pool Size'].clear()\n",
    "data['Epochs'].clear()\n",
    "data['Test Accuracy'].clear()\n",
    "data['Model Size'].clear()\n",
    "data['History Plot'].clear()\n",
    "\n",
    "lists = [learning_rate, optimizer, filters, kernel_size, strides, pool_size, conv_dropout_rate, fc_dropout_rate, conv_batch_normalization, fc_batch_normalization, activations, units, epochs]\n",
    "\n",
    "all_permutations = build_permutations(lists)\n",
    "\n",
    "for idx, permutation in enumerate(all_permutations, start=1):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    model, accuracy = preprocess_build_train_test('./data/cropped_1/', \n",
    "                                                  './data/test_cropped_1/', \n",
    "                                                  normalize=True, \n",
    "                                                  learning_rate=permutation[0], \n",
    "                                                  optimizer=permutation[1],\n",
    "                                                  epochs=permutation[12]    ,\n",
    "                                                  num_conv = 2, \n",
    "                                                  filters = permutation[2], \n",
    "                                                  kernel_size = permutation[3], \n",
    "                                                  strides = permutation[4], \n",
    "                                                  pool_size = permutation[5], \n",
    "                                                  pool_names = ['pool_1', 'pool_2'], \n",
    "                                                  conv_dropout_rate= permutation[6], \n",
    "                                                  fc_dropout_rate = permutation[7],\n",
    "                                                  conv_batch_normalization = permutation[8], \n",
    "                                                  fc_batch_normalization = permutation[9],\n",
    "                                                  activations = permutation[10], \n",
    "                                                  num_dense = 3, \n",
    "                                                  units = permutation[11], \n",
    "                                                  conv_layer_names = ['conv_1', 'conv_2'],\n",
    "                                                  fc_layer_names =['fc_1', 'fc_2', 'fc_3', 'output'],\n",
    "                                                  history_plot_file=f'{plot_dir}/history_{idx}.png')\n",
    "    \n",
    "    model_ff_list.append(model)\n",
    "\n",
    "                                                    \n",
    "    data['Learning Rate'].append(permutation[0])\n",
    "    data['Filters'].append(permutation[2])\n",
    "    data['Kernel Size'].append(permutation[3])\n",
    "    data['Strides'].append(permutation[4])\n",
    "    data['optimizer'].append(permutation[1])\n",
    "    data['Conv Dropout Rate'].append(permutation[6])\n",
    "    data['FC Dropout Rate'].append(permutation[7])\n",
    "    data['Units'].append(permutation[11])\n",
    "    data['Pool Size'].append(permutation[5])\n",
    "    data['Epochs'].append(permutation[12])\n",
    "    data['Test Accuracy'].append(accuracy)\n",
    "    data['Model Size'].append(get_model_size(model))\n",
    "    data['History Plot'].append(FileLink(f'{plot_dir}/history_{idx}.png'))    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if idx % 5 == 0:\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        \n",
    "        df.to_excel(output_file, index=False)\n",
    "\n",
    "        display(df)\n",
    "        \n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test images\n",
    "\n",
    "def predict_drowsy(model, dir_path, normalize=True, num_images=50):\n",
    "\n",
    "    image_test, label_test = data_preprocess_step1(dir_path, num_images=num_images)\n",
    "    np.random.seed(1235)\n",
    "    shuffle = np.random.permutation(np.arange(image_test.shape[0]))\n",
    "    image_test, label_test = image_test[shuffle], label_test[shuffle]\n",
    "    image_test = tf.image.resize(image_test, size=(80,80))\n",
    "    if normalize:\n",
    "        image_test = image_test/255.0\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    pred_logits = model.predict(image_test)\n",
    "    probas = tf.sigmoid(pred_logits)\n",
    "    probas = probas.numpy().flatten()*100\n",
    "\n",
    "\n",
    "    # Create a figure to display the test images and their predictions\n",
    "    fig = plt.figure(figsize=(10, 50))\n",
    "\n",
    "    # Iterate over each test example\n",
    "    for j, example in enumerate(image_test):\n",
    "        ax = fig.add_subplot(int(len(label_test)/4),4, j+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(array_to_img(example))\n",
    "        \n",
    "        # Determine the ground truth label and the predicted probability of being drowsy\n",
    "        if label_test[j]==0:\n",
    "            label='Non Drowsy'\n",
    "        else:\n",
    "            label='Drowsy'\n",
    "        \n",
    "        # Display the ground truth label and the predicted probability\n",
    "        ax.text(\n",
    "            0.5, -0.15, \n",
    "            'GT: {:s}\\nPr(Drowsy)={:.0f}%'.format(label, probas[j]), \n",
    "            size=10, \n",
    "            color='black',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return image_test, label_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test, label_test = predict_drowsy(model_ff_list[0], 'data/manual_annotate/test/', normalize=True, num_images=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def plot_filters(model, img_tensor, layer_num):\n",
    "\n",
    "    # outputs of the first 4 layers, which include conv2D and max pooling layers\n",
    "    layer_outputs = [layer.output for layer in model.layers[:layer_num]]\n",
    "    activation_model = Model(inputs = model.input, outputs = layer_outputs)\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "\n",
    "    # grab layer names\n",
    "    layer_names = []\n",
    "    for layer in model.layers[:layer_num]:\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "    # getting activations of each layer\n",
    "    for idx, layer in enumerate(activations):\n",
    "        if idx in (0,1):\n",
    "            print('----------------')\n",
    "            print('Geeting activations of layer',  idx+1, ':', layer_names[idx])\n",
    "            activation = layer\n",
    "\n",
    "            # shape of layer activation\n",
    "            print('Images size is', activation.shape[1], 'x', activation.shape[2])\n",
    "            print('Number of channels is', activation.shape[3])\n",
    "\n",
    "            # print channels\n",
    "            print('Printing channels:')\n",
    "            \n",
    "            # define nrows and ncols depending on number of channels\n",
    "            if idx in (0,1):\n",
    "                nrows, ncols = 4,4\n",
    "            if idx in (2,3):\n",
    "                nrows, ncols = 8,8\n",
    "\n",
    "            # plots\n",
    "            channel=0\n",
    "            if idx in (0,1):\n",
    "                f, axs = plt.subplots(nrows, ncols, figsize=(32,28))\n",
    "            if idx in (2,3):\n",
    "                f, axs = plt.subplots(nrows, ncols, figsize=(16,20))\n",
    "                \n",
    "            for i in range(nrows):\n",
    "                for j in range(ncols):\n",
    "                    if i==0 and j==0:\n",
    "                        channel=0\n",
    "                    else:\n",
    "                        channel+=1\n",
    "\n",
    "                    im = axs[i,j].matshow(activation[0,:, :, channel], cmap ='viridis')\n",
    "                    axs[i,j].set(title=str(channel))\n",
    "                    plt.colorbar(im, ax=axs[i, j], fraction=0.046, pad=0.04)\n",
    "                    axs[i,j].axis('on') # pay attention to the range of x and y axis\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_NUM = 5\n",
    "\n",
    "\n",
    "img_tensor = np.expand_dims(image_test[IMG_NUM], axis = 0)\n",
    "# Print image tensor shape\n",
    "print('Shape of image:', img_tensor.shape)  \n",
    "# Print image\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.title('label:' + str(label_test[IMG_NUM]))\n",
    "plt.show()\n",
    "\n",
    "plot_filters(model_ff_list[0], img_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_drowsy('/Users/mayank/Downloads/face2/face/', normalize=True, num_images=5)\n",
    "image_test, label_test = predict_drowsy(model_eye_list[4], './data/cropped_1', normalize=True, num_images=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_NUM = 5\n",
    "\n",
    "\n",
    "img_tensor = np.expand_dims(image_test[IMG_NUM], axis = 0)\n",
    "# Print image tensor shape\n",
    "print('Shape of image:', img_tensor.shape)  \n",
    "# Print image\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.title('label:' + str(label_test[IMG_NUM]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filters(model_eye_list[0], img_tensor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Models Experimented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T22:59:10.327428Z",
     "start_time": "2023-11-24T22:59:10.325385Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_modelV1():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2), name='pool_2')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1024,\n",
    "        name='fc_1', \n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=0.5))\n",
    "\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='fc_2',\n",
    "        activation=None))\n",
    "    \n",
    "    # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modelV3():\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Adding first three convolutional layers\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu', # activation function \n",
    "                    input_shape = (80,80,3) # shape of input (image)\n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "\n",
    "    # Adding pooling after convolutional layers\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2))) # Dimensions of the region that you are pooling\n",
    "\n",
    "    # Adding second set of convolutional layers\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "                    filters = 32, # number of filters\n",
    "                    kernel_size = (3,3), # height/width of filter\n",
    "                    activation = 'relu' # activation function \n",
    "                    ))\n",
    "\n",
    "    # Add last pooling layer.\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Adding first dense layer with 256 nodes\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "    # Adding a dropout layer to avoid overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3)) \n",
    "\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    # adding output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation = None))\n",
    "\n",
    "        # build model and print summary\n",
    "    tf.random.set_seed(1)\n",
    "    model.build(input_shape=(None, 80, 80, 3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aditional utility function to predict images in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T23:03:37.334475Z",
     "start_time": "2023-11-24T23:03:34.898451Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "def predict(model, img):\n",
    "    img= keras.utils.load_img(\n",
    "        img, target_size=(80, 80))\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = img_array/255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "dir_path = \"data/manual_annotate/test/Drowsy/S0040.png\"\n",
    "predictions = predict(model, dir_path)\n",
    "print (predictions)\n",
    "'''\n",
    "i = 0\n",
    "file_path = []\n",
    "prediction_results = []\n",
    "for file_name in os.listdir(dir_path):\n",
    "    \n",
    "    predictions = predict(model, dir_path+file_name)\n",
    "    \n",
    "    print (predictions)\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    probabilities = tf.nn.sigmoid(predictions).numpy()\n",
    "    \n",
    "    prediction_results.append(probabilities[0])\n",
    "    file_path.append(dir_path+file_name)\n",
    "\n",
    "\n",
    "\n",
    "data = {'file_path': file_path, 'prediction_results': prediction_results}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "# Display the dataframe with filepath as a link to the image\n",
    "for index, row in df.iterrows():\n",
    "    display(Image(filename=row['file_path']))\n",
    "    print(row)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Define the grid size based on the number of images\n",
    "num_images = len(df)\n",
    "grid_size = int(num_images ** 0.5) + 1\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axs = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "\n",
    "# Iterate over the dataframe rows and display the image with prediction result\n",
    "for index, row in df.iterrows():\n",
    "    img = plt.imread(row['file_path'])\n",
    "    ax = axs[index // grid_size, index % grid_size]\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Prediction: {row['prediction_results']:.2f}\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(num_images, grid_size ** 2):\n",
    "    axs[i // grid_size, i % grid_size].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(np.array(prediction_results))\n",
    "array = np.array(prediction_results)\n",
    "print(np.size(array))\n",
    "\n",
    "um_elements_greater_than_zero = np.sum(array > 0)\n",
    "\n",
    "print (um_elements_greater_than_zero)\n",
    "\n",
    "um_elements_less_than_zero = np.sum(array < 0)\n",
    "print (um_elements_less_than_zero)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "learning_rate               =   [0.001,\n",
    "                                 0.01]\n",
    " \n",
    "optimizer                   =   ['adam',\n",
    "                                 'adagrad', \n",
    "                                 'sgd']\n",
    "                                 \n",
    "                        \n",
    "filters                     =   [[16,16],\n",
    "                                 [16,8],\n",
    "                                 [8,16], \n",
    "                                 [8,8]] \n",
    "\n",
    "kernel_size                 =   [[(5,5),(5,5)], \n",
    "                                 [(3,3),(3,3)], \n",
    "                                 [(3,3),(5,5)], \n",
    "                                 [(5,5),(3,3)]]\n",
    " \n",
    "strides                     =   [[(1,1),(1,1)], \n",
    "                                 [(2,2),(2,2)]]\n",
    "\n",
    "pool_size                   =   [[(2,2),(2,2)]]\n",
    "                        \n",
    "conv_dropout_rate           =   [[0.3, 0.5]]\n",
    "\n",
    "fc_dropout_rate             =   [[0.5, 0, 0]]\n",
    "\n",
    "conv_batch_normalization    =   [[True, True]]\n",
    "\n",
    "fc_batch_normalization      =   [[False, True, True]]\n",
    "\n",
    "activations                 =   [['relu', 'relu', 'relu', 'relu', 'relu']]\n",
    "                        \n",
    "units                       =   [[128, 64, 32],\n",
    "                                 [64, 64, 32]]\n",
    "\n",
    "epochs                      =   [10, 20, 30, 40]\n",
    "\n",
    "\n",
    "def build_permutations(lists):\n",
    "\n",
    "    # Generate permutations of one element from each list\n",
    "    all_permutations = list(product(*lists))\n",
    "\n",
    "    # Print the permutations\n",
    "    for idx, permutation in enumerate(all_permutations, start=1):\n",
    "        print(f\"Permutation {idx}: {permutation}\")\n",
    "\n",
    "\n",
    "    permutation = all_permutations[0]\n",
    "    print(permutation[0])\n",
    "\n",
    "lists = [learning_rate, optimizer, filters, kernel_size, strides, pool_size, conv_dropout_rate, fc_dropout_rate, conv_batch_normalization, fc_batch_normalization, activations, units, epochs]\n",
    "build_permutations(lists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
